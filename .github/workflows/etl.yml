name: Run ETL Time Travel

on:
  workflow_dispatch:
    inputs:
      origen:
        description: "Origen desde donde se descargan los archivos"
        default: "https://d37ci6vzurychx.cloudfront.net/trip-data"
      archivos:
        description: "Archivos a ser procesados"
        default: "yellow_tripdata_2020-01.parquet,yellow_tripdata_2021-01.parquet,yellow_tripdata_2022-01.parquet"
      class:
        type: choice
        description: Clase java desde la que ejecuta el ETL
        options:
          - com.taxis.etl.travel_time.TravelTime
          - com.taxis.etl.payments_distance.PaymentsDistance
        default: com.taxis.etl.travel_time.TravelTime
      hilos:
        description: "Numero de hilos de procesador"
        default: "1"
      pi:
        description: "Spark Pi Program"
        default: "100"

env:
  TAXIS_ETL_FILES: ${{ github.event.inputs.archivos }}
  TAXIS_ETL_DOWNLOAD_FOLDER: downloads
  TAXIS_ETL_BASE_URL: ${{ github.event.inputs.origen }}
  TAXIS_ETL_DOWNLOAD_FILES: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout project sources
      uses: actions/checkout@v3
    - name: Setup Gradle
      uses: gradle/gradle-build-action@v2
    - uses: vemonet/setup-spark@v1
      with:
        spark-version: '3.1.2'
        hadoop-version: '2.7'
    - run: spark-submit --version
    - name: Run build with Gradle Wrapper
      run: ./gradlew assemble
    - run: mkdir ./downloads
    - name: Run spark submit for ${{ github.event.inputs.class }}
      run: spark-submit --class ${{ github.event.inputs.class }} --master local[${{ github.event.inputs.hilos }}] build/libs/taxisEtl.jar ${{ github.event.inputs.pi }}
    - name: Archive ETL results
      uses: actions/upload-artifact@v3
      with:
        name: results
        path: results
